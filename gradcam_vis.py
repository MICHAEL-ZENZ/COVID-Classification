from model import Densenet, Inceptionv3, ResNet, VGG,SimpleCNN, Deeplabv3from utils import grad_cam,utilsimport torch.nn as nnimport PILimport osfrom torchvision.utils import make_grid, save_imageimport argparseimport torchimport torch.nn.functional as Ffrom tqdm import tqdmimport timefrom torchvision import transformsclass MaskModel(nn.Module):    def __init__(self,basemodel):        super(MaskModel, self).__init__()        if isinstance(basemodel,ResNet.ResNet):            conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2,                                                 padding=3, bias=False)            features = [conv1, basemodel.bn1, basemodel.relu, basemodel.maxpool,                        basemodel.layer1, basemodel.layer2, basemodel.layer3, basemodel.layer4]            self.features = nn.Sequential(*features)        elif isinstance(basemodel,Densenet.DenseNet):            basemodel.features.conv0 = nn.Conv2d(4, 64, kernel_size=7, stride=2,                                padding=3, bias=False)            self.features = nn.Sequential(basemodel.features,                                         nn.ReLU(inplace=True))        self.fc = basemodel.fc    def forward(self, x, mask):        x = torch.cat([x,mask],dim=1)        feature = self.features(x)        feature = F.adaptive_avg_pool2d(feature, (1, 1))        feature = torch.flatten(feature, 1)        pred = self.fc(feature)        return predMODEL_DICT = {    'densenet121': Densenet.densenet121,    'densenet161': Densenet.densenet161,    'densenet169': Densenet.densenet169,    'resnet18': ResNet.resnet18,    'resnet50': ResNet.resnet50,    'wide_resnet101': ResNet.wide_resnet101_2,    'vgg16': VGG.vgg16,    'CNN': SimpleCNN.CNN,    'Linear': SimpleCNN.Linear,    'SimpleCNN': SimpleCNN.SimpleCNN}MODEL_NAME_DICT = {        'densenet121': 'densenet',        'densenet161': 'densenet',        'densenet169': 'densenet',        'resnet18': 'resnet',        'resnet50': 'resnet',        'wide_resnet101': 'resnet',        'vgg16': 'vgg'    }FEATURES = {'resnet': 'layer4',            'vgg': 'features_29',            'densenet': 'module_classifier_6'}def gradcam_vis(model,in_img_path,out_img_path,model_name,device,in_mask_path=None):    model_type = MODEL_NAME_DICT[model_name]    model.eval()    pil_img = PIL.Image.open(in_img_path).convert('RGB')    normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],                                     std=[0.33165374, 0.33165374, 0.33165374])    test_trans = transforms.Compose(        [transforms.Resize((480, 480)),         transforms.ToTensor()]    )    torch_img = test_trans(pil_img)    normed_torch_img = normalize(torch_img).unsqueeze(0).float().to(device)    densenet_model_dict = dict(type=model_type, arch=model, layer_name=FEATURES[model_type], input_size=(480, 480))    print('Layer:{}'.format(FEATURES[model_type]))    if in_mask_path:        lung_mask = PIL.Image.open(in_mask_path).convert('L')        torch_lung_mask = test_trans(lung_mask).unsqueeze(0).float().to(device)        gradcam = grad_cam.GradCAMMaskin(densenet_model_dict)        mask, _ = gradcam(normed_torch_img, torch_lung_mask, class_idx=0)    else:        gradcam = grad_cam.GradCAM(densenet_model_dict)        mask, _ = gradcam(normed_torch_img)    images = []    heatmap, result = utils.visualize_cam(mask.cpu(), torch_img)    images.append(torch.stack([torch_img.squeeze().cpu(), heatmap, result], 0))    images = make_grid(torch.cat(images, 0), nrow=3)    save_image(images, out_img_path)def batch_gradcam_vis(args, model, device, num_plot = 100):    for img_name in tqdm(os.listdir(args.gradcam_inpath)[:num_plot]):        if img_name.endswith('png') or img_name.endswith('jpg'):            in_img_path = os.path.join(args.gradcam_inpath, img_name)            out_img_path = os.path.join(args.gradcam_outpath,args.gradcam_inpath.split('/')[-1], args.save_name.split('.')[0], img_name)            gradcam_vis(model, in_img_path=in_img_path, out_img_path=out_img_path,                        model_name=args.model_name, device=device)def batch_gradcam_vis_maskin(args, model, device, num_plot = 100):    for img_name in tqdm(os.listdir(args.gradcam_inpath)[:num_plot]):        if img_name.endswith('png') or img_name.endswith('jpg'):            in_img_path = os.path.join(args.gradcam_inpath, img_name)            in_mask_path = os.path.join(args.gradmask_inpath, img_name)            out_img_path = os.path.join(args.gradcam_outpath,args.gradcam_inpath.split('/')[-1], args.save_name.split('.')[0], img_name)            gradcam_vis(model, in_img_path=in_img_path, out_img_path=out_img_path,                        model_name=args.model_name, device=device, in_mask_path=in_mask_path)def batch_gradcam_vis_modellist(args, models, device, num_plot = 10):    normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],                                     std=[0.33165374, 0.33165374, 0.33165374])    test_trans = transforms.Compose(        [            transforms.Resize((480,480)),            transforms.ToTensor()        ]    )    for img_name in tqdm(os.listdir(args.gradcam_inpath)[:num_plot]):        if img_name.endswith('png') or img_name.endswith('jpg'):            in_img_path = os.path.join(args.gradcam_inpath, img_name)            pil_img = PIL.Image.open(in_img_path).convert('RGB')            torch_img = test_trans(pil_img)            normed_torch_img = normalize(torch_img).unsqueeze(0).float().to(device)            images = [torch_img.squeeze().cpu()]            images_list = []            for model_id in range(len(models)):                model = models[model_id]                model_type = MODEL_NAME_DICT[args.model_name]                model.eval()                print('Layer:{}'.format(FEATURES[model_type]))                densenet_model_dict = dict(type=model_type,                                           arch=model,                                           layer_name=FEATURES[model_type],                                           input_size=(224, 224))                gradcam = grad_cam.GradCAM(densenet_model_dict, True)                mask, _ = gradcam(normed_torch_img)                heatmap, result = utils.visualize_cam(mask.cpu(), torch_img)                images.append(heatmap)                images.append(result)            images_list.append(torch.stack(images, 0))            images_list = make_grid(torch.cat(images_list, 0), nrow=7)            out_img_path = os.path.join(args.gradcam_outpath,args.model_name, img_name)            save_image(images_list, out_img_path)def main():    parser = argparse.ArgumentParser(description='COVID-19 CT Classification.')    parser.add_argument('--model-name', type=str, default='densenet169')    parser.add_argument('--checkpoint-path', type=str, default='./checkpoint/CT')    parser.add_argument('--save-name', type=str, default='densenet169_480_deeplabv3_mask input|covid output_newdata_pretrained.pt')    parser.add_argument('--gradcam-inpath', type=str, default='../data/dataset_5_5.5/data/4_4_data_crop/CT_COVID')    parser.add_argument('--gradcam-outpath', type=str, default='./gradcam_vis')    parser.add_argument('--gradcam-imgname', type=str, default='30%4.jpg')    args = parser.parse_args()    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")    print("Device {}".format(device))    # Create checkpoint file    out_dir = os.path.join(args.gradcam_outpath,args.gradcam_inpath.split('/')[-1], args.save_name.split('.')[0])    if os.path.exists(out_dir) == False:        os.makedirs(out_dir)    nb_classes = 2    seg_num_class = 2    print(args.model_name)    model = MODEL_DICT[args.model_name](num_classes=nb_classes).to(device)    if torch.cuda.device_count() > 1:        print("Let's use", torch.cuda.device_count(), "GPUs!")        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs        model = nn.DataParallel(model).to(device)    save_path = os.path.join(args.checkpoint_path, args.model_name)    save = os.path.join(save_path, '{}'.format(args.save_name))    model.load_state_dict(torch.load(save))    print("Model Loaded...........................")    print('GradCam................................')    batch_gradcam_vis(args,model,device)def main_maskin():    parser = argparse.ArgumentParser(description='COVID-19 CT Classification.')    parser.add_argument('--model-name', type=str, default='densenet169')    parser.add_argument('--checkpoint-path', type=str, default='./checkpoint/CT')    parser.add_argument('--save-name', type=str, default='densenet169_480_deeplabv3_mask input|covid output_newdata_pretrained.pt')    parser.add_argument('--gradcam-inpath', type=str, default='../data/dataset_5_5.5/data/4_4_data_crop/CT_COVID')    parser.add_argument('--gradmask-inpath', type=str, default='../data/dataset_5_5.5/data/med_seg_lungmask/CT_COVID')    parser.add_argument('--gradcam-outpath', type=str, default='./gradcam_vis')    parser.add_argument('--gradcam-imgname', type=str, default='30%4.jpg')    args = parser.parse_args()    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")    print("Device {}".format(device))    # Create checkpoint file    out_dir = os.path.join(args.gradcam_outpath,args.gradcam_inpath.split('/')[-1], args.save_name.split('.')[0])    if os.path.exists(out_dir) == False:        os.makedirs(out_dir)    nb_classes = 2    seg_num_class = 2    print(args.model_name)    model = MODEL_DICT[args.model_name](num_classes=nb_classes).to(device)    # model = MaskModel(model)    model = Deeplabv3.DeeplabV3maskin(model,num_class=seg_num_class)    # print(model)    if torch.cuda.device_count() > 1:        print("Let's use", torch.cuda.device_count(), "GPUs!")        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs        model = nn.DataParallel(model).to(device)    save_path = os.path.join(args.checkpoint_path, args.model_name)    save = os.path.join(save_path, '{}'.format(args.save_name))    model.load_state_dict(torch.load(save))    print("Model Loaded...........................")    print('GradCam................................')    batch_gradcam_vis_maskin(args,model,device)def main_Xray():    parser = argparse.ArgumentParser(description='COVID-19 Xray Classification.')    parser.add_argument('--model-name', type=str, default='resnet50')    parser.add_argument('--checkpoint-path', type=str, default='./checkpoint/X-ray')    parser.add_argument('--save-name', type=str, default='resnet50_moco_weight_pretrained.pt')    parser.add_argument('--gradcam-inpath', type=str, default='../COVID-Net/data/test/')    parser.add_argument('--gradcam-outpath', type=str, default='./gradcam_vis/Xray')    parser.add_argument('--gradcam-imgname', type=str, default='30%4.jpg')    args = parser.parse_args()    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")    print("Device {}".format(device))    # Create checkpoint file    out_dir = os.path.join(args.gradcam_outpath, args.save_name.split('.')[0])    if os.path.exists(out_dir) == False:        os.makedirs(out_dir)    nb_classes = 3    print(args.model_name)    model = MODEL_DICT[args.model_name](num_classes=nb_classes).to(device)    save_path = os.path.join(args.checkpoint_path, args.model_name)    save = os.path.join(save_path, '{}'.format(args.save_name))    model.load_state_dict(torch.load(save))    print("Model Loaded...........................")    print('GradCam................................')    batch_gradcam_vis(args,model,device)def main_compare():    '''    random, pretrained, Moco    ['densenet169_4_4_crop_randinit.pt','densenet169_4_4_crop_pretrained.pt','densenet169-moco-COVID.pt']    ['resnet50_4_4_crop_randinit.pt','resnet50_4_4_crop_pretrained.pt','resnet50-moco-COVID.pt']    '''    parser = argparse.ArgumentParser(description='COVID-19 CT Classification.')    parser.add_argument('--model-name', type=str, default='resnet50')    parser.add_argument('--checkpoint-path', type=str, default='./checkpoint/CT')    parser.add_argument('--save-name', type=list, default=['resnet50_4_4_crop_randinit.pt','resnet50_4_4_crop_pretrained.pt','resnet50-moco-COVID.pt'])    parser.add_argument('--gradcam-inpath', type=str, default='../data/4_4_data_crop/CT_COVID')    parser.add_argument('--gradcam-outpath', type=str, default='./gradcam_vis')    args = parser.parse_args()    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")    print("Device {}".format(device))    # Create checkpoint file    out_dir = os.path.join(args.gradcam_outpath, args.model_name)    if os.path.exists(out_dir) == False:        os.makedirs(out_dir)    nb_classes = 2    print(args.model_name)    models = []    for name in args.save_name:        print("Model Loaded {}...........................".format(name))        print('GradCam................................')        model = MODEL_DICT[args.model_name](num_classes=nb_classes).to(device)        save_path = os.path.join(args.checkpoint_path, args.model_name)        save = os.path.join(save_path, '{}'.format(name))        mes = model.load_state_dict(torch.load(save))        models.append(model)    batch_gradcam_vis_modellist(args,models,device)if __name__ == '__main__':    main_maskin()