import torchfrom torch.utils.data import Datasetimport osfrom PIL import Imageimport numpy as npimport torchvision.transforms as transformsimport randomimport cv2def read_txt(txt_path):    with open(txt_path) as f:        lines = f.readlines()    txt_data = [line.strip() for line in lines]    return txt_dataclass CenterCrop(object):    def __init__(self,arg):        self.transform = transforms.CenterCrop(arg)    def __call__(self, sample):        img, label, label2 = sample        if label2:            return self.transform(img), self.transform(label), self.transform(label2)        else:            return self.transform(img),self.transform(label), Noneclass Resize(object):    def __init__(self,arg):        self.transform_img = transforms.Resize(arg,Image.BILINEAR)        self.transform_label = transforms.Resize(arg,Image.NEAREST)    def __call__(self, sample):        img, label, label2= sample        if label2:            return self.transform_img(img), self.transform_label(label), self.transform_label(label2)        else:            return self.transform_img(img), self.transform_label(label),Noneclass Normalize(object):    def __init__(self,mean,std):        self.transform = transforms.Normalize(mean, std)    def __call__(self, sample):        img, label = sample        return self.transform(img),labelclass ToTensor(object):    def __init__(self):        pass    def __call__(self, sample):        img, label = sample        label = np.array(label)/255        img = np.array(img)        img = (img-img.min())/(img.max()-img.min())        return torch.from_numpy(img.transpose((2, 0, 1))).float(),torch.from_numpy(label.copy()).long()class RandomRescale(object):    def __init__(self,min_ratio=0.5,max_ratio=1.0):        self.min_ratio = min_ratio        self.max_ratio = max_ratio    def __call__(self, sample):        img, label, label2 = sample        width, height = img.size        ratio = random.uniform(self.min_ratio,self.max_ratio)        new_width, new_height = int(ratio*width), int(ratio*height)        if label2:            return img.resize((new_width, new_height)), label.resize((new_width, new_height)), label2.resize((new_width, new_height))        else:            return img.resize((new_width, new_height)), label.resize((new_width, new_height)), Noneclass RandomFlip(object):    def __init__(self,p=0.5):        self.p = p    def __call__(self, sample):        img, label, label2 = sample        if random.uniform(0,1)>self.p:            if label2:                return transforms.functional.hflip(img),transforms.functional.hflip(label),transforms.functional.hflip(label2)            else:                return transforms.functional.hflip(img), transforms.functional.hflip(                    label), None        else:            return img, label, label2class RandomColor(object):    def __init__(self,brightness=0.2,contrast=0.2,saturation=0.2,hue=0.2):        self.transform = transforms.ColorJitter(brightness,contrast,saturation,hue)    def __call__(self, sample):        img, label, label2 = sample        img = self.transform(img)        return img, label, label2class RandomRotation(object):    def __init__(self, degree=(-10,10)):        self.degree = degree    def __call__(self, sample):        img, label, label2 = sample        angle = transforms.RandomRotation.get_params(self.degree)        img = transforms.functional.rotate(img, angle,resample = Image.BILINEAR)        label = transforms.functional.rotate(label, angle)        if label2:            label2 = transforms.functional.rotate(label2, angle)        return img, label, label2class RandomCrop(object):    def __init__(self,output_size,fill=0, padding_mode='constant'):        self.output_size = output_size        self.fill = fill        self.padding_mode = padding_mode        self.pad_if_needed = True    def __call__(self, sample):        img, label, label2 = sample        # pad the width if needed        if self.pad_if_needed and img.size[0] < self.output_size[1]:            img = transforms.functional.pad(img, (self.output_size[1] - img.size[0], 0), self.fill, self.padding_mode)            label = transforms.functional.pad(label, (self.output_size[1] - label.size[0], 0), self.fill, self.padding_mode)            if label2:                label2 = transforms.functional.pad(label2, (self.output_size[1] - label2.size[0], 0), self.fill, self.padding_mode)        # pad the height if needed        if self.pad_if_needed and img.size[1] < self.output_size[0]:            img = transforms.functional.pad(img, (0, self.output_size[0] - img.size[1]), self.fill, self.padding_mode)            label = transforms.functional.pad(label, (0, self.output_size[0] - label.size[1]), self.fill, self.padding_mode)            if label2:                label2 = transforms.functional.pad(label2, (0, self.output_size[0] - label2.size[1]), self.fill, self.padding_mode)        i, j, h, w = transforms.RandomCrop.get_params(            img, output_size=self.output_size)        img = transforms.functional.crop(img, i, j, h, w)        label = transforms.functional.crop(label, i, j, h, w)        if label2:            label2 = transforms.functional.crop(label2, i, j, h, w)        return img, label, label2class CovidCTSegDataset(Dataset):    """Covid XRay dataset."""    def __init__(self, root_dir, mask_dir, txt_COVID, txt_NonCOVID, norm = (0.45271412,0.33165374),size_transform = None, img_transform=None):        """        Args:            txt_path (string): Path to the txt file with annotations.            root_dir (string): Directory with all the images.            transform (callable, optional): Optional transform to be applied                on a sample.        File structure:        - root_dir            - CT_COVID                - img1.png                - img2.png                - ......            - CT_NonCOVID                - img1.png                - img2.png                - ......        """        self.root_dir = root_dir        self.mask_dir = mask_dir        self.txt_path = [txt_COVID,txt_NonCOVID]        self.classes = ['CT_COVID', 'CT_NonCOVID']        self.num_cls = len(self.classes)        self.img_list = []        self.norm = norm        self.mask_list = []        for c in range(self.num_cls):            self.mask_list += [[os.path.join(self.mask_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]            self.img_list += [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]        self.size_transform = size_transform        self.img_transform = img_transform    def __len__(self):        return len(self.img_list)    def __getitem__(self, idx):        if torch.is_tensor(idx):            idx = idx.tolist()        img_path = self.img_list[idx][0]        mask_path = self.mask_list[idx][0]        image = Image.open(img_path).convert('RGB')        mask = Image.open(mask_path).convert('L')        if self.size_transform:            image,mask,_ = self.size_transform((image, mask, None))        mask = np.array(mask)/255        mask = torch.from_numpy(mask.copy()).unsqueeze(0).float()        mask = (mask-self.norm[0])/self.norm[1]        if self.img_transform:            image = self.img_transform(image)        sample = {'img': image,                  'mask': mask,                  'label': int(self.img_list[idx][1])}        return sampleclass CovidCTSegTaskDataset(Dataset):    """Covid XRay dataset."""    def __init__(self, root_dir, mask_dir, covid_mask_dir, txt_COVID, txt_NonCOVID, size_transform = None, img_transform=None):        """        Args:            txt_path (string): Path to the txt file with annotations.            root_dir (string): Directory with all the images.            transform (callable, optional): Optional transform to be applied                on a sample.        File structure:        - root_dir            - CT_COVID                - img1.png                - img2.png                - ......            - CT_NonCOVID                - img1.png                - img2.png                - ......        """        self.root_dir = root_dir        self.mask_dir = mask_dir        self.covid_mask_dir = covid_mask_dir        self.txt_path = [txt_NonCOVID,txt_COVID]        self.classes = ['CT_NonCOVID','CT_COVID']        self.num_cls = len(self.classes)        self.img_list = []        self.mask_list = []        self.covid_mask_list = []        for c in range(self.num_cls):            self.mask_list += [[os.path.join(self.mask_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]            self.img_list += [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]            self.covid_mask_list += [[os.path.join(self.covid_mask_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]        self.size_transform = size_transform        self.img_transform = img_transform    def __len__(self):        return len(self.img_list)    def __getitem__(self, idx):        if torch.is_tensor(idx):            idx = idx.tolist()        img_path = self.img_list[idx][0]        lung_mask_path = self.mask_list[idx][0]        mask_path = self.covid_mask_list[idx][0]        image = Image.open(img_path).convert('RGB')        lung_mask = Image.open(lung_mask_path).convert('L')        if os.path.exists(mask_path):            mask = Image.open(mask_path).convert('L')            if self.size_transform:                image, lung_mask, mask = self.size_transform((image, lung_mask, mask))            lung_mask = np.array(lung_mask) / 255            lung_mask = torch.from_numpy(lung_mask.copy())            mask = np.array(mask)            mask[mask>0]=1            seg = True        else:            if self.size_transform:                image, lung_mask, mask = self.size_transform((image, lung_mask, None))            seg = False            lung_mask = np.array(lung_mask) / 255            lung_mask = torch.from_numpy(lung_mask.copy())            mask = np.zeros_like(lung_mask)        mask = torch.from_numpy(mask.copy()).type(torch.FloatTensor)        if self.img_transform:            image = self.img_transform(image)        sample = {'img': image,                  'mask': lung_mask,                  'label': int(self.img_list[idx][1]),                  'covid': mask,                  'seg': seg                  }        return sampleif __name__ == '__main__':    normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],                                     std=[0.33165374, 0.33165374, 0.33165374])    # trainset = CovidCTSegDataset(root_dir='F:\covid-19\COVID-CT\dataset_4_26_with_seg\\4_4_data_crop',    #                              mask_dir='F:\covid-19\COVID-CT\dataset_4_26_with_seg\\4_4_data_crop_mask',    #                             txt_COVID='F:\covid-19\COVID-CT\dataset_4_4\\4_4_txt_crop\\testCT_COVID.txt',    #                             txt_NonCOVID='F:\covid-19\COVID-CT\dataset_4_4\\4_4_txt_crop\\testCT_NonCOVID.txt',    #                              size_transform=transforms.Compose(    #                                  [    #                                      RandomRescale(0.5, 1.2),    #                                      RandomRotation(),    #                                      RandomCrop((480, 480)),    #                                      RandomFlip()    #                                  ]    #                              ),    #                              img_transform=transforms.Compose(    #                                  [transforms.ToTensor(),    #                                   normalize]    #                              )    #                              )    trainset = CovidCTSegTaskDataset(root_dir='F:\covid-19\COVID-CT\dataset_4_27_with_seg\images',                                 mask_dir='F:\covid-19\COVID-CT\dataset_4_27_with_seg\lung_mask',                                 covid_mask_dir='F:\covid-19\COVID-CT\dataset_4_27_with_seg\mask',                                 txt_COVID='F:\covid-19\COVID-CT\dataset_4_27_with_seg\\4_4_txt_crop\\trainCT_COVID.txt',                                 txt_NonCOVID='F:\covid-19\COVID-CT\dataset_4_27_with_seg\\4_4_txt_crop\\trainCT_NonCOVID.txt',                                 size_transform=transforms.Compose(                                     [                                         RandomRescale(0.5, 1.2),                                         RandomRotation(),                                         RandomCrop((480, 480)),                                         RandomFlip()                                     ]                                 ),                                 img_transform=transforms.Compose(                                     [transforms.ToTensor(),                                      normalize]                                 )                                 )    trainset.__getitem__(400)