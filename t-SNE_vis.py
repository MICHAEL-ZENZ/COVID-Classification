from sklearn import manifoldimport numpy as npimport matplotlib.pyplot as pltfrom model import Densenet, Inceptionv3, ResNet, VGG, SimpleCNN, Efficientnet, COVIDNetfrom utils import CovidXRayDataset,metrics,CovidCTDatasetfrom torch.utils.data import DataLoaderimport argparseimport torchimport torch.nn.functional as Ffrom tqdm import tqdmimport timeimport osfrom torchvision import transformsimport numpy as npclass Feature_model(object):    def __init__(self, model_dict, verbose=False):        model_type = model_dict['type']        layer_name = model_dict['layer_name']        self.model_arch = model_dict['arch']        self.gradients = dict()        self.activations = dict()        def backward_hook(module, grad_input, grad_output):            self.gradients['value'] = grad_output[0]            return None        def forward_hook(module, input, output):            self.activations['value'] = output            return None        if 'covid_net' in model_type.lower():            target_layer = self.model_arch.flatten        if 'vgg' in model_type.lower():            target_layer = None        elif 'resnet' in model_type.lower():            target_layer = self.model_arch.layer4        elif 'densenet' in model_type.lower():            target_layer = self.model_arch.features        elif 'alexnet' in model_type.lower():            target_layer = None        elif 'squeezenet' in model_type.lower():            target_layer = None        target_layer.register_forward_hook(forward_hook)        if verbose:            try:                input_size = model_dict['input_size']            except KeyError:                print("please specify size of input image in model_dict. e.g. {'input_size':(224, 224)}")                pass            else:                device = 'cuda' if next(self.model_arch.parameters()).is_cuda else 'cpu'                self.model_arch(torch.zeros(1, 3, *(input_size), device=device))                print('saliency_map size :', self.activations['value'].shape[2:])    def forward(self, input, class_idx=None, retain_graph=False):        """        Args:            input: input image with shape of (1, 3, H, W)            class_idx (int): class index for calculating GradCAM.                    If not specified, the class index that makes the highest model prediction score will be used.        Return:            mask: saliency map of the same spatial dimension with input            logit: model output        """        logit = self.model_arch(input)        activations = self.activations['value']        return activations    def __call__(self, input, class_idx=None, retain_graph=False):        return self.forward(input, class_idx, retain_graph)MODEL_DICT = {    'densenet121': Densenet.densenet121,    'densenet161': Densenet.densenet161,    'densenet169': Densenet.densenet169,    'resnet18': ResNet.resnet18,    'resnet50': ResNet.resnet50,    'wide_resnet101': ResNet.wide_resnet101_2,    'vgg16': VGG.vgg16,    'COVIDNet_small': COVIDNet.covid_net_small,    'COVIDNet_large': COVIDNet.covid_net_large,    'CNN': SimpleCNN.CNN,    'Linear': SimpleCNN.Linear,    'SimpleCNN': SimpleCNN.SimpleCNN,    'efficientnet-b7': Efficientnet.efficientnetb7,    'efficientnet-b1': Efficientnet.efficientnetb1,    'efficientnet-b0': Efficientnet.efficientnetb0}MODEL_NAME_DICT = {        'densenet121': 'densenet',        'densenet161': 'densenet',        'densenet169': 'densenet',        'resnet18': 'resnet',        'resnet50': 'resnet',        'wide_resnet101': 'resnet',        'vgg16': 'vgg',        'COVIDNet_small': 'covid_net',        'COVIDNet_large': 'covid_net',    }FEATURES = {'resnet': 'layer4',            'vgg': 'features_29',            'densenet': 'features_norm5',            'covid_net': 'flatten'            }def test(model, nb_classes, test_loader, args, device):    model.eval()    predlist = []    targetlist = []    model_type = MODEL_NAME_DICT[args.model_name]    model_dict = dict(type=model_type, arch=model, layer_name=FEATURES[model_type], input_size=(224, 224))    feature_model = Feature_model(model_dict)    with torch.no_grad():        for index, batch in enumerate(tqdm(test_loader)):            img, label = batch['img'].to(device), batch['label'].to(device)            output = feature_model(img)            output = torch.flatten(output, 1)            predlist.append(output.cpu().numpy())            targetlist = np.append(targetlist, label.long().cpu().numpy())    predlist = np.concatenate(predlist)    return predlist,targetlistdef main_Xray(path):    parser = argparse.ArgumentParser(description='COVID-19 X-ray Classification.')    parser.add_argument('--model-name',  type=str, default='COVIDNet_large')    parser.add_argument('--checkpoint-path',type = str, default='./checkpoint/X-ray')    parser.add_argument('--batch-size', type = int, default=32)    parser.add_argument('--lr', type=float, default=1e-4)    parser.add_argument('--epoch',type = int ,default=50)    parser.add_argument('--train-txt',type=str, default='train_split_v3.txt')    parser.add_argument('--test-txt',type=str, default='test_split_v3.txt')    parser.add_argument('--train-dir',type=str,default='../COVID-Net/data/train/')    parser.add_argument('--test-dir',type=str,default='../COVID-Net/data/test/')    parser.add_argument('--pretrained', default='../moco/COVID_COVIDNet_large_1024_rand_Xray/checkpoint_0120.pth.tar', type=str,                    help='path to moco pretrained checkpoint') # ../moco/COVID_COVIDNet_small_4096_rand_Xray/checkpoint_0040.pth.tar    parser.add_argument('--save-name',type=str, default='COVIDNet_small_moco_weight_randinit.pt')    parser.add_argument('--class-weight',type=list, default=[1.,1.,2.])    parser.add_argument('--img-name', type=str, default='t-SNE-vis/t-SNE-COVIDNet_large-MoCo120_Xray.png')    args = parser.parse_args()    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")    print("Device {}\tModel {}".format(device,args.model_name))    # Create checkpoint file    save_path = os.path.join(args.checkpoint_path, args.model_name)    if os.path.exists(save_path) == False:        os.makedirs(save_path)    trainset = CovidXRayDataset(txt_path=args.train_txt,                                root_dir=args.train_dir,                                transform=transforms.Compose(                                    [transforms.Resize((256,256)),                                     transforms.RandomResizedCrop((224,224),                                                                  scale=(0.5, 1.25)),                                     transforms.RandomHorizontalFlip(),                                     transforms.ToTensor(),                                     transforms.Normalize((0.5, 0.5, 0.5),                                                          (0.5, 0.5, 0.5))]                                ))    testset = CovidXRayDataset(txt_path=args.test_txt,                               root_dir=args.test_dir,                               transform=transforms.Compose(                                   [transforms.Resize((224,224)),                                    transforms.ToTensor(),                                    transforms.Normalize((0.5,0.5,0.5),                                                         (0.5, 0.5, 0.5))]                               )                               )    train_loader = DataLoader(trainset,                              batch_size=args.batch_size,                              shuffle=True,                              num_workers=4)    test_loader = DataLoader(testset,batch_size=args.batch_size)    nb_classes = 3    model = MODEL_DICT[args.model_name](num_classes=nb_classes, pretrained=False).to(device)    save = os.path.join(save_path, '{}'.format(args.save_name))    if args.pretrained:        if os.path.isfile(args.pretrained):            print("=> loading checkpoint '{}'".format(args.pretrained))            checkpoint = torch.load(args.pretrained, map_location="cpu")            # rename moco pre-trained keys            state_dict = checkpoint['state_dict']            for k in list(state_dict.keys()):                # retain only encoder_q up to before the embedding layer                if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):                    # remove prefix                    state_dict[k[len("module.encoder_q."):]] = state_dict[k]                # delete renamed or unused k                del state_dict[k]            args.start_epoch = 0            msg = model.load_state_dict(state_dict, strict=False)            # assert set(msg.missing_keys) == {"fc.weight", "fc.bias"}            print("=> loaded pre-trained model '{}'".format(args.pretrained))        else:            print("=> no checkpoint found at '{}'".format(args.pretrained))    # init the fc layer    model.fc.weight.data.normal_(mean=0.0, std=0.01)    model.fc.bias.data.zero_()    print("UnFreeze Model")    for name, param in model.named_parameters():        param.requires_grad = True    print('...........Testing..........')    print(save)    feature, label = test(model, nb_classes, test_loader, args, device)    print(feature.shape,label.shape)    X = {        'data':feature,        'label':label    }    t_SNE(X, nb_classes, args)def main_CT(path=None):    parser = argparse.ArgumentParser(description='COVID-19 CT Classification.')    parser.add_argument('--model-name',  type=str, default='densenet169')    parser.add_argument('--checkpoint-path',type = str, default='./checkpoint/CT')    parser.add_argument('--batch-size', type = int, default=16)    parser.add_argument('--lr', type=float, default=1e-4)    parser.add_argument('--epoch',type = int ,default=50)    parser.add_argument('--root-dir',type=str,default='../data/4_4_data_crop')    parser.add_argument('--train-COV',type=str,default='../data/4_4_txt_crop/trainCT_COVID.txt')    parser.add_argument('--train-NonCOV',type=str,default='../data/4_4_txt_crop/trainCT_NonCOVID.txt')    parser.add_argument('--val-COV',type=str,default='../data/4_4_txt_crop/valCT_COVID.txt')    parser.add_argument('--val-NonCOV',type=str,default='../data/4_4_txt_crop/valCT_NonCOVID.txt')    parser.add_argument('--test-COV',type=str,default='../data/4_4_txt_crop/testCT_COVID.txt')    parser.add_argument('--test-NonCOV',type=str,default='../data/4_4_txt_crop/testCT_NonCOVID.txt')    parser.add_argument('--pretrained', default='', type=str,                    help='path to moco pretrained checkpoint')#'../moco/COVID_ResNet50_512_imagenet/checkpoint_{}.pth.tar'.format(path)    parser.add_argument('--save-name',type=str, default='densenet169-480-moco-COVID.pt')    parser.add_argument('--img-name',type=str, default='t-SNE-vis/t-SNE-densenet169-mocofinal_CT.png')# 't-SNE-vis/t-SNE-resnet50-MoCo{}_CT.png'.format(path)    args = parser.parse_args()    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")    print("Device {}".format(device))    # Create checkpoint file    save_path = os.path.join(args.checkpoint_path, args.model_name)    if os.path.exists(save_path) == False:        os.makedirs(save_path)    normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],                                     std=[0.33165374, 0.33165374, 0.33165374])    test_trans = transforms.Compose(                                 [transforms.Resize((224,224)),                                  transforms.ToTensor(),                                  normalize]                             )    trainset = CovidCTDataset(root_dir=args.root_dir,                              txt_COVID=args.train_COV,                              txt_NonCOVID=args.train_NonCOV,                                transform=transforms.Compose(                                    [transforms.Resize((256,256)),                                     transforms.RandomResizedCrop((224,224),                                                                  scale=(0.5, 1.25)),                                     transforms.RandomHorizontalFlip(),                                     transforms.ToTensor(),                                     normalize]                                ))    valset = CovidCTDataset(root_dir=args.root_dir,                            txt_COVID=args.val_COV,                            txt_NonCOVID=args.val_NonCOV,                             transform=test_trans                             )    testset = CovidCTDataset(root_dir=args.root_dir,                             txt_COVID=args.test_COV,                             txt_NonCOVID=args.test_NonCOV,                               transform=test_trans                               )    train_loader = DataLoader(trainset,                              batch_size=args.batch_size,                              shuffle=True)    val_loader = DataLoader(valset, batch_size=args.batch_size)    test_loader = DataLoader(testset,batch_size=args.batch_size)    PRINT_INTERVAL = 5    nb_classes = 2    print(args.model_name,trainset.classes)    model = MODEL_DICT[args.model_name](num_classes=nb_classes,pretrained = False).to(device)    if args.pretrained:        if os.path.isfile(args.pretrained):            print("=> loading checkpoint '{}'".format(args.pretrained))            checkpoint = torch.load(args.pretrained, map_location="cpu")            # rename moco pre-trained keys            state_dict = checkpoint['state_dict']            for k in list(state_dict.keys()):                # retain only encoder_q up to before the embedding layer                if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):                    # remove prefix                    state_dict[k[len("module.encoder_q."):]] = state_dict[k]                # delete renamed or unused k                del state_dict[k]            args.start_epoch = 0            msg = model.load_state_dict(state_dict, strict=False)            # assert set(msg.missing_keys) == {"fc.weight", "fc.bias"}            print("=> loaded pre-trained model '{}'".format(args.pretrained))        else:            print("=> no checkpoint found at '{}'".format(args.pretrained))    # init the fc layer    model.fc.weight.data.normal_(mean=0.0, std=0.01)    model.fc.bias.data.zero_()    print("UnFreeze Model")    for name, param in model.named_parameters():        param.requires_grad = True    print('...........Testing..........')    feature, label = test(model, nb_classes, test_loader, args, device)    print(feature.shape,label.shape)    X = {        'data':feature,        'label':label    }    t_SNE(X,nb_classes, args)def plot_embedding(X, digits, number_class, args , title=None):    plt.figure()    colors = ['blue', 'red' ,'black']    for i in range(number_class):        idx = np.where(digits['label'] == i)        plt.scatter(X[idx, 0], X[idx, 1], color=colors[i], label=str(i))    plt.legend(loc='lower right', fontsize=12)    if title is not None:        plt.title(title, fontsize=18)    plt.savefig(args.img_name)    print('done')def t_SNE(X,number_class, args):    tsne = manifold.TSNE(n_components=number_class,init='pca')    X_tsne = tsne.fit_transform(X['data'])    plot_embedding(X_tsne, X, number_class, args,                   "t-SNE")if __name__ == "__main__":    main_CT()