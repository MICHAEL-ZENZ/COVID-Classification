{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Densenet, Inceptionv3, ResNet, VGG, SimpleCNN, Efficientnet, ResNeSt, Ensemble,SeResNet, Deeplabv3\n",
    "from model import prunnableResNet\n",
    "from model.layer.prunableLayer import prunnableConv2D,prunnableLinear\n",
    "from utils import CovidCTDataset,metrics, SimCLR_loss, LabelSmoothSoftmaxCE\n",
    "from utils import autoaugment as auto\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import easydict\n",
    "\n",
    "import gc\n",
    "\n",
    "MODEL_DICT = {\n",
    "    'densenet121': Densenet.densenet121,\n",
    "    'densenet161': Densenet.densenet161,\n",
    "    'densenet169': Densenet.densenet169,\n",
    "    'densenet201': Densenet.densenet201,\n",
    "    'resnet18': ResNet.resnet18,\n",
    "    'resnet50': ResNet.resnet50,\n",
    "    'resnet101': ResNet.resnet101,\n",
    "    'resnet152': ResNet.resnet152,\n",
    "    'seresnet50': SeResNet.se_resnet50,\n",
    "    'seresnet101': SeResNet.se_resnet101,\n",
    "    'seresnet152': SeResNet.se_resnet152,\n",
    "    'resnext101': ResNet.resnext101_32x8d,\n",
    "    'resnest50': ResNeSt.resnest50,\n",
    "    'resnest200': ResNeSt.resnest200,\n",
    "    'wide_resnet101': ResNet.wide_resnet101_2,\n",
    "    'wide_resnet50': ResNet.wide_resnet50_2,\n",
    "    'vgg16': VGG.vgg16,\n",
    "    'CNN': SimpleCNN.CNN,\n",
    "    'Linear': SimpleCNN.Linear,\n",
    "    'SimpleCNN': SimpleCNN.SimpleCNN,\n",
    "    'efficientnet-b7': Efficientnet.efficientnetb7,\n",
    "    'efficientnet-b1': Efficientnet.efficientnetb1,\n",
    "    'efficientnet-b0': Efficientnet.efficientnetb0\n",
    "}\n",
    "\n",
    "PRUNNABLE_MODEL_DICT={\n",
    "    'resnet18':prunnableResNet.resnet18,\n",
    "    'resnet50':prunnableResNet.resnet50,\n",
    "    'resnet101':prunnableResNet.resnet101,\n",
    "    'resnet152':prunnableResNet.resnet152\n",
    "}\n",
    "\n",
    "def train(model, train_loader, optimizer, PRINT_INTERVAL, epoch, args, device):\n",
    "    model.train()\n",
    "    # LOSS_FUNC = LabelSmoothSoftmaxCE()\n",
    "    LOSS_FUNC = nn.CrossEntropyLoss()\n",
    "    for index, batch in enumerate(tqdm(train_loader)):\n",
    "        img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "        output = model(img)\n",
    "        optimizer.zero_grad()\n",
    "        loss = LOSS_FUNC(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (index + 1) % PRINT_INTERVAL == 0:\n",
    "            tqdm.write('Epoch [%d/%d], Iter [%d/%d], Loss: %.4f'\n",
    "                       % (epoch + 1, args.epoch, index + 1, len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, nb_classes, test_loader, device):\n",
    "    model.eval()\n",
    "    predlist = []\n",
    "    targetlist = []\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    avg_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(tqdm(test_loader)):\n",
    "            img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "            output = model(img)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            avg_val_loss += F.cross_entropy(output, label).item()/len(test_loader)\n",
    "            for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "            y_score = F.softmax(output, dim=1)\n",
    "            predlist = np.append(predlist, y_score.cpu().numpy()[:, 1])\n",
    "            targetlist = np.append(targetlist, label.long().cpu().numpy())\n",
    "\n",
    "    AUC = roc_auc_score(targetlist, predlist)\n",
    "    print(confusion_matrix)\n",
    "    precision = metrics.Precision(confusion_matrix.cpu().numpy(), nb_classes)\n",
    "    recall = metrics.Recall(confusion_matrix, nb_classes)\n",
    "    f1 = metrics.f1_score(precision, recall)\n",
    "    acc = metrics.Acc(confusion_matrix,nb_classes)\n",
    "\n",
    "    return AUC, precision, recall, f1, acc, avg_val_loss\n",
    "\n",
    "def test_mask(model, nb_classes, test_loader, device):\n",
    "    model.eval()\n",
    "    predlist = []\n",
    "    targetlist = []\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    avg_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(tqdm(test_loader)):\n",
    "            img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "            cls_pred, mask_pred = model(img)\n",
    "            _, preds = torch.max(cls_pred, 1)\n",
    "\n",
    "            avg_val_loss += F.cross_entropy(cls_pred, label).item()/len(test_loader)\n",
    "            for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "            y_score = F.softmax(cls_pred, dim=1)\n",
    "            predlist = np.append(predlist, y_score.cpu().numpy()[:, 1])\n",
    "            targetlist = np.append(targetlist, label.long().cpu().numpy())\n",
    "\n",
    "    AUC = roc_auc_score(targetlist, predlist)\n",
    "    print(confusion_matrix)\n",
    "    precision = metrics.Precision(confusion_matrix.cpu().numpy(), nb_classes)\n",
    "    recall = metrics.Recall(confusion_matrix, nb_classes)\n",
    "    f1 = metrics.f1_score(precision, recall)\n",
    "    acc = metrics.Acc(confusion_matrix,nb_classes)\n",
    "\n",
    "    return AUC, precision, recall, f1, acc, avg_val_loss\n",
    "\n",
    "def convertPaWeights2NonP(pretrained_state_dict):\n",
    "  nonpStateDict=OrderedDict()\n",
    "  for k, v in pretrained_state_dict.items():\n",
    "    nonpStateDict[k[7:]]=v\n",
    "  return nonpStateDict\n",
    "\n",
    "def convertStateDict2Prunnable(state_dict):\n",
    "    prunedStateDict=OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if 'conv' in k or 'downsample.0' in k:\n",
    "            p=k.find('.weight')\n",
    "            k=k[:p]+'.conv'+k[p:]\n",
    "\n",
    "        prunedStateDict[k]=v\n",
    "    return prunedStateDict\n",
    "\n",
    "models_config = (\n",
    "    # model name, model path, weight, data_parallel\n",
    "    ('resnet152', 'resnet152_4_4_crop_480_b16_pretrained.pt', 1, True),\n",
    "    ('resnet152', 'resnet152_4_4_crop_480_b16w1.2_pretrained.pt', 1, True),\n",
    "    ('resnext101', 'resnext101_4_4_crop_480_pretrained.pt', 1, True),\n",
    "    ('densenet169', 'densenet169-480-moco-soft-COVID.pt', 1, True),\n",
    "    ('densenet169', 'densenet169_4_4_crop_480_b16_pretrained.pt', 1, True),\n",
    "    ('densenet169', 'densenet169_soft_480_pretrained.pt', 1, True),\n",
    ")\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'model_name':'resnet50',\n",
    "    'checkpoint_path':'./checkpoint/CT',\n",
    "    'batch_size':16,\n",
    "    'lr':1e-4,\n",
    "    'epoch':50,\n",
    "    'root_dir':'./COVID-CT/Images-processed',\n",
    "\n",
    "    'train_COV':'./COVID-CT/Data-split/COVID/trainCT_COVID.txt',\n",
    "    'train_NonCOV':'./COVID-CT/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "\n",
    "    'val_COV':'./COVID-CT/Data-split/COVID/valCT_COVID.txt',\n",
    "    'val_NonCOV':'./COVID-CT/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "\n",
    "    'test_COV':'./COVID-CT/Data-split/COVID/testCT_COVID.txt',\n",
    "    'test_NonCOV':'./COVID-CT/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "\n",
    "    'pretrained':True,\n",
    "    'save_name':'resnet50_pretrained.pt'\n",
    "})\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device {}\".format(device))\n",
    "# Create checkpoint file\n",
    "save_path = os.path.join(args.checkpoint_path, args.model_name)\n",
    "if os.path.exists(save_path) == False:\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],\n",
    "                                    std=[0.33165374, 0.33165374, 0.33165374])\n",
    "test_trans = transforms.Compose(\n",
    "                                [\n",
    "                                transforms.Resize((480,480)),\n",
    "                                transforms.ToTensor(),\n",
    "                                normalize\n",
    "                                ]\n",
    "                            )\n",
    "trainset = CovidCTDataset(root_dir=args.root_dir,\n",
    "                            txt_COVID=args.train_COV,\n",
    "                            txt_NonCOVID=args.train_NonCOV,\n",
    "                            transform=transforms.Compose(\n",
    "                                [transforms.RandomResizedCrop((480,480),scale=(0.8,1.2)),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    auto.ImageNetPolicy(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    normalize\n",
    "                                    ]\n",
    "                            ))\n",
    "valset = CovidCTDataset(root_dir=args.root_dir,\n",
    "                        txt_COVID=args.val_COV,\n",
    "                        txt_NonCOVID=args.val_NonCOV,\n",
    "                            transform=test_trans\n",
    "                            )\n",
    "\n",
    "testset = CovidCTDataset(root_dir=args.root_dir,\n",
    "                            txt_COVID=args.test_COV,\n",
    "                            txt_NonCOVID=args.test_NonCOV,\n",
    "                            transform=test_trans\n",
    "                            )\n",
    "\n",
    "train_loader = DataLoader(trainset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            num_workers=8,\n",
    "                            shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(testset,batch_size=args.batch_size)\n",
    "\n",
    "PRINT_INTERVAL = 10\n",
    "nb_classes = 2\n",
    "seg_num_class = 2\n",
    "print(args.model_name,trainset.classes)\n",
    "\n",
    "model = PRUNNABLE_MODEL_DICT[args.model_name](num_classes=nb_classes, pretrained=args.pretrained)\n",
    "\n",
    "accs = []\n",
    "save = os.path.join(save_path,'{}'.format(args.save_name))\n",
    "\n",
    "print('...........Testing..........')\n",
    "pretrained_state_dict=torch.load(save, map_location=torch.device('cpu'))\n",
    "if not torch.cuda.is_available():\n",
    "    pretrained_state_dict=convertPaWeights2NonP(pretrained_state_dict)\n",
    "model.load_state_dict(convertStateDict2Prunnable(pretrained_state_dict))\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model).to(device)\n",
    "elif torch.cuda.device_count() == 1:\n",
    "    model.to(device)\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"GPU detected but cannot use\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratios=[i/100 for i in range(0,91,10)]\n",
    "yconvACC,yconvFN=[],[]\n",
    "ydenseACC,ydenseFN=[],[]\n",
    "for m in model.modules():\n",
    "    yACC=[]\n",
    "    yFN=[]\n",
    "    \n",
    "    if isinstance(m, (prunnableConv2D,prunnableLinear)):\n",
    "        print(m) \n",
    "        for r in ratios:\n",
    "            m.setPruneRatio(r)\n",
    "            print('prune ratio:%f'%r)\n",
    "            AUC, precision, recall, f1, acc, mean_loss = test(model, 2, test_loader, device)\n",
    "            print('Precision {}\\tRecall {}\\nF1 {}\\nAUC {}\\tAcc {}\\tMean Loss {}'.format(precision, recall, f1, AUC, acc,\n",
    "                                                                            mean_loss))\n",
    "            yACC.append(acc)\n",
    "            yFN.append(recall[1])\n",
    "            m.resetPruneRatio()\n",
    "    if isinstance(m,prunnableConv2D):\n",
    "        yconvACC.append(yACC)\n",
    "        yconvFN.append(yFN)\n",
    "    elif isinstance(m,prunnableLinear):\n",
    "        ydenseACC.append(yACC)\n",
    "        ydenseFN.append(yFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yconvACC_bak,yconvFN_bak=yconvACC.copy(),yconvFN.copy()\n",
    "ydenseACC_bak,ydenseFN.bak=ydenseACC.copy(),ydenseFN.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(8):\n",
    "#     if yacc[i]==np.nan:yacc[i]=0\n",
    "#     if yFNs[i]==np.nan:yFNs[i]=0\n",
    "\n",
    "for yACC in yconvACC:\n",
    "    plt.plot(ratios, yACC)\n",
    "\n",
    "plt.show()\n",
    "# plt.legend([\"R1=\"+str(i/8) for i in range(1,9)], loc='lower right')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}