{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Densenet, Inceptionv3, ResNet, VGG, SimpleCNN, Efficientnet, ResNeSt, Ensemble,SeResNet, Deeplabv3\n",
    "from model import dcpResNet\n",
    "from utils import CovidCTDataset,metrics, SimCLR_loss, LabelSmoothSoftmaxCE\n",
    "from utils import autoaugment as auto\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import easydict\n",
    "\n",
    "MODEL_DICT = {\n",
    "    'densenet121': Densenet.densenet121,\n",
    "    'densenet161': Densenet.densenet161,\n",
    "    'densenet169': Densenet.densenet169,\n",
    "    'densenet201': Densenet.densenet201,\n",
    "    'resnet18': ResNet.resnet18,\n",
    "    'resnet50': ResNet.resnet50,\n",
    "    'resnet101': ResNet.resnet101,\n",
    "    'resnet152': ResNet.resnet152,\n",
    "    'seresnet50': SeResNet.se_resnet50,\n",
    "    'seresnet101': SeResNet.se_resnet101,\n",
    "    'seresnet152': SeResNet.se_resnet152,\n",
    "    'resnext101': ResNet.resnext101_32x8d,\n",
    "    'resnest50': ResNeSt.resnest50,\n",
    "    'resnest200': ResNeSt.resnest200,\n",
    "    'wide_resnet101': ResNet.wide_resnet101_2,\n",
    "    'wide_resnet50': ResNet.wide_resnet50_2,\n",
    "    'vgg16': VGG.vgg16,\n",
    "    'CNN': SimpleCNN.CNN,\n",
    "    'Linear': SimpleCNN.Linear,\n",
    "    'SimpleCNN': SimpleCNN.SimpleCNN,\n",
    "    'efficientnet-b7': Efficientnet.efficientnetb7,\n",
    "    'efficientnet-b1': Efficientnet.efficientnetb1,\n",
    "    'efficientnet-b0': Efficientnet.efficientnetb0\n",
    "}\n",
    "\n",
    "DCP_MODEL_DICT={\n",
    "    'resnet18':dcpResNet.resnet18,\n",
    "    'resnet50':dcpResNet.resnet50,\n",
    "    'resnet101':dcpResNet.resnet101,\n",
    "    'resnet152':dcpResNet.resnet152\n",
    "}\n",
    "\n",
    "def train(model, train_loader, optimizer, PRINT_INTERVAL, epoch, args, device):\n",
    "    model.train()\n",
    "    # LOSS_FUNC = LabelSmoothSoftmaxCE()\n",
    "    LOSS_FUNC = nn.CrossEntropyLoss()\n",
    "    for index, batch in enumerate(tqdm(train_loader)):\n",
    "        img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "        output = model(img)\n",
    "        optimizer.zero_grad()\n",
    "        loss = LOSS_FUNC(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (index + 1) % PRINT_INTERVAL == 0:\n",
    "            tqdm.write('Epoch [%d/%d], Iter [%d/%d], Loss: %.4f'\n",
    "                       % (epoch + 1, args.epoch, index + 1, len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, nb_classes, test_loader, device):\n",
    "    model.eval()\n",
    "    predlist = []\n",
    "    targetlist = []\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    avg_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(tqdm(test_loader)):\n",
    "            img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "            output = model(img)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            avg_val_loss += F.cross_entropy(output, label).item()/len(test_loader)\n",
    "            for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "            y_score = F.softmax(output, dim=1)\n",
    "            predlist = np.append(predlist, y_score.cpu().numpy()[:, 1])\n",
    "            targetlist = np.append(targetlist, label.long().cpu().numpy())\n",
    "\n",
    "    AUC = roc_auc_score(targetlist, predlist)\n",
    "    print(confusion_matrix)\n",
    "    precision = metrics.Precision(confusion_matrix.cpu().numpy(), nb_classes)\n",
    "    recall = metrics.Recall(confusion_matrix, nb_classes)\n",
    "    f1 = metrics.f1_score(precision, recall)\n",
    "    acc = metrics.Acc(confusion_matrix,nb_classes)\n",
    "\n",
    "    return AUC, precision, recall, f1, acc, avg_val_loss\n",
    "\n",
    "def test_mask(model, nb_classes, test_loader, device):\n",
    "    model.eval()\n",
    "    predlist = []\n",
    "    targetlist = []\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    avg_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(tqdm(test_loader)):\n",
    "            img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "            cls_pred, mask_pred = model(img)\n",
    "            _, preds = torch.max(cls_pred, 1)\n",
    "\n",
    "            avg_val_loss += F.cross_entropy(cls_pred, label).item()/len(test_loader)\n",
    "            for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "            y_score = F.softmax(cls_pred, dim=1)\n",
    "            predlist = np.append(predlist, y_score.cpu().numpy()[:, 1])\n",
    "            targetlist = np.append(targetlist, label.long().cpu().numpy())\n",
    "\n",
    "    AUC = roc_auc_score(targetlist, predlist)\n",
    "    print(confusion_matrix)\n",
    "    precision = metrics.Precision(confusion_matrix.cpu().numpy(), nb_classes)\n",
    "    recall = metrics.Recall(confusion_matrix, nb_classes)\n",
    "    f1 = metrics.f1_score(precision, recall)\n",
    "    acc = metrics.Acc(confusion_matrix,nb_classes)\n",
    "\n",
    "    return AUC, precision, recall, f1, acc, avg_val_loss\n",
    "\n",
    "def convertPaWeights2NonP(pretrained_state_dict):\n",
    "  nonpStateDict=OrderedDict()\n",
    "  for k, v in pretrained_state_dict.items():\n",
    "    nonpStateDict[k[7:]]=v\n",
    "  return nonpStateDict\n",
    "\n",
    "def buildAndTestDCPmodel(model_name, preTrainedModel, test_loader, device, R1_ratio, R2_ratio):\n",
    "    dcpModel=DCP_MODEL_DICT[model_name](num_classes=2, R1_ratio=R1_ratio, R2_ratio=R2_ratio)\n",
    "    dcpModel.loadStateFromModel(preTrainedModel)\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        dcpModel = nn.DataParallel(dcpModel).to(device)\n",
    "    elif torch.cuda.device_count()==1:\n",
    "        dcpModel.to(device)\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"GPU detected but cannot use\")\n",
    "    \n",
    "    AUC, precision, recall, f1, acc, mean_loss = test(dcpModel, 2, test_loader, device)\n",
    "\n",
    "    print('Precision {}\\tRecall {}\\nF1 {}\\nAUC {}\\tAcc {}\\tMean Loss {}'.format(precision, recall, f1, AUC, acc,\n",
    "                                                                                mean_loss))\n",
    "\n",
    "    return acc, recall[1]\n",
    "\n",
    "def saveDCPweights(model_name, preTrainedModel, test_loader, device, R1_ratio, R2_ratio):\n",
    "    dcpModel=DCP_MODEL_DICT[model_name](num_classes=2, R1_ratio=R1_ratio, R2_ratio=R2_ratio)\n",
    "    dcpModel.loadStateFromModel(preTrainedModel)\n",
    "    \n",
    "    save=\"checkpoint/CT/%s/%s_R1_%.3f_R2_%.3f.pt\"%(model_name,model_name,R1_ratio,R2_ratio)\n",
    "    print('saving to %s'%(save))\n",
    "    torch.save(dcpModel.state_dict(),save)\n",
    "\n",
    "def testAndLoadFromChkpt(model_name, preTrainedModel, test_loader, device, R1_ratio, R2_ratio):\n",
    "    dcpModel=DCP_MODEL_DICT[model_name](num_classes=2, R1_ratio=R1_ratio, R2_ratio=R2_ratio)\n",
    "    save=\"checkpoint/CT/%s/%s_R1_%.3f_R2_%.3f.pt\"%(model_name,model_name,R1_ratio,R2_ratio)\n",
    "    state_dict=torch.load(save)\n",
    "    dcpModel.load_state_dict(state_dict)\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        dcpModel = nn.DataParallel(dcpModel).to(device)\n",
    "    elif torch.cuda.device_count()==1:\n",
    "        dcpModel.to(device)\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"GPU detected but cannot use\")\n",
    "    \n",
    "    AUC, precision, recall, f1, acc, mean_loss = test(dcpModel, 2, test_loader, device)\n",
    "\n",
    "    print('Precision {}\\tRecall {}\\nF1 {}\\nAUC {}\\tAcc {}\\tMean Loss {}'.format(precision, recall, f1, AUC, acc,\n",
    "                                                                                mean_loss))\n",
    "\n",
    "    return acc, recall[1]\n",
    "\n",
    "\n",
    "print(\"Start training\")\n",
    "models_config = (\n",
    "    # model name, model path, weight, data_parallel\n",
    "    ('resnet152', 'resnet152_4_4_crop_480_b16_pretrained.pt', 1, True),\n",
    "    ('resnet152', 'resnet152_4_4_crop_480_b16w1.2_pretrained.pt', 1, True),\n",
    "    ('resnext101', 'resnext101_4_4_crop_480_pretrained.pt', 1, True),\n",
    "    ('densenet169', 'densenet169-480-moco-soft-COVID.pt', 1, True),\n",
    "    ('densenet169', 'densenet169_4_4_crop_480_b16_pretrained.pt', 1, True),\n",
    "    ('densenet169', 'densenet169_soft_480_pretrained.pt', 1, True),\n",
    ")\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'model_name':'resnet50',\n",
    "    'checkpoint_path':'./checkpoint/CT',\n",
    "    'batch_size':16,\n",
    "    'lr':1e-4,\n",
    "    'epoch':50,\n",
    "    'root_dir':'./COVID-CT/Images-processed',\n",
    "\n",
    "    'train_COV':'./COVID-CT/Data-split/COVID/trainCT_COVID.txt',\n",
    "    'train_NonCOV':'./COVID-CT/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "\n",
    "    'val_COV':'./COVID-CT/Data-split/COVID/valCT_COVID.txt',\n",
    "    'val_NonCOV':'./COVID-CT/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "\n",
    "    'test_COV':'./COVID-CT/Data-split/COVID/testCT_COVID.txt',\n",
    "    'test_NonCOV':'./COVID-CT/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "\n",
    "    'pretrained':True,\n",
    "    'save_name':'resnet50_pretrained.pt'\n",
    "})\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device {}\".format(device))\n",
    "# Create checkpoint file\n",
    "save_path = os.path.join(args.checkpoint_path, args.model_name)\n",
    "if os.path.exists(save_path) == False:\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],\n",
    "                                 std=[0.33165374, 0.33165374, 0.33165374])\n",
    "test_trans = transforms.Compose(\n",
    "                             [\n",
    "                              transforms.Resize((480,480)),\n",
    "                              transforms.ToTensor(),\n",
    "                              normalize\n",
    "                             ]\n",
    "                         )\n",
    "trainset = CovidCTDataset(root_dir=args.root_dir,\n",
    "                          txt_COVID=args.train_COV,\n",
    "                          txt_NonCOVID=args.train_NonCOV,\n",
    "                            transform=transforms.Compose(\n",
    "                                [transforms.RandomResizedCrop((480,480),scale=(0.8,1.2)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 auto.ImageNetPolicy(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 normalize\n",
    "                                 ]\n",
    "                            ))\n",
    "valset = CovidCTDataset(root_dir=args.root_dir,\n",
    "                        txt_COVID=args.val_COV,\n",
    "                        txt_NonCOVID=args.val_NonCOV,\n",
    "                         transform=test_trans\n",
    "                         )\n",
    "\n",
    "testset = CovidCTDataset(root_dir=args.root_dir,\n",
    "                         txt_COVID=args.test_COV,\n",
    "                         txt_NonCOVID=args.test_NonCOV,\n",
    "                           transform=test_trans\n",
    "                           )\n",
    "\n",
    "train_loader = DataLoader(trainset,\n",
    "                          batch_size=args.batch_size,\n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(testset,batch_size=args.batch_size)\n",
    "\n",
    "PRINT_INTERVAL = 10\n",
    "nb_classes = 2\n",
    "seg_num_class = 2\n",
    "print(args.model_name,trainset.classes)\n",
    "\n",
    "model = MODEL_DICT[args.model_name](num_classes=nb_classes, pretrained=args.pretrained)\n",
    "\n",
    "# model = Deeplabv3.DeeplabVV3(model, num_class=seg_num_class)\n",
    "if torch.cuda.device_count() >= 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model).to(device)\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"GPU detected but cannot use\")\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = args.lr)\n",
    "sheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "# sheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_max=10)\n",
    "# sheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=15)\n",
    "accs = []\n",
    "save = os.path.join(save_path,'{}'.format(args.save_name))\n",
    "\n",
    "if not args.pretrained:\n",
    "  for epoch in range(args.epoch):\n",
    "    train(model, train_loader, optimizer, PRINT_INTERVAL, epoch, args, device)\n",
    "\n",
    "    AUC, precision, recall, f1, acc, mean_loss = test(model, nb_classes, val_loader, device)\n",
    "    accs.append(acc)\n",
    "    print('Precision {}\\tRecall {}\\nF1 {}\\nAUC {}\\tAcc {}\\tMean Loss {}'.format(precision, recall, f1, AUC, acc, mean_loss))\n",
    "\n",
    "    if np.max(accs) == acc:\n",
    "        torch.save(model.state_dict(), save)\n",
    "        print(\"saved\")\n",
    "    sheduler.step(epoch)\n",
    "\n",
    "print('...........Testing..........')\n",
    "pretrained_state_dict=torch.load(save, map_location=torch.device('cpu'))\n",
    "if not torch.cuda.is_available():\n",
    "  pretrained_state_dict=convertPaWeights2NonP(pretrained_state_dict)\n",
    "model.load_state_dict(pretrained_state_dict)\n",
    "\n",
    "testAndLoadFromChkpt(args.model_name, model, test_loader, device, 1.0,1.0)\n",
    "yacc,yFNs=[],[]\n",
    "for dR1 in range(1,9):\n",
    "    yacc.append([])\n",
    "    yFNs.append([])\n",
    "    print(\"Starting R1=%.3f\"%(dR1/8))\n",
    "    for dR2 in range(1,9):\n",
    "        r1,r2=dR1/8,dR2/8\n",
    "        print(\"R1=%.3f, R2=%.3f\"%(r1,r2))\n",
    "        acc,FN=testAndLoadFromChkpt(args.model_name, model, test_loader, device, r1, r2)\n",
    "        # acc,FN=buildAndTestDCPmodel(args.model_name, model, test_loader, device, r1, r2)\n",
    "        gc.collect()\n",
    "        yacc[-1].append(acc)\n",
    "        yFNs[-1].append(FN)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yacc_bak=yacc.copy()\n",
    "yFNs_bak=yFNs.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[d/8 for d in range(1,9)]\n",
    "\n",
    "yacc,yFNs=yacc_bak.copy(), yFNs_bak.copy()\n",
    "yacc=np.nan_to_num(yacc)\n",
    "yFNs=np.nan_to_num(yFNs,nan=1.0)\n",
    "\n",
    "for i in range(8):\n",
    "    plt.plot(x, yacc[i])\n",
    "for i in range(8):\n",
    "    plt.plot(x,yFNs[i], linestyle='--')\n",
    "plt.legend([\"R1=\"+str(i/8) for i in range(1,9)]+[\"R1=\"+str(i/8) for i in range(1,9)], loc='lower left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
