{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Densenet, Inceptionv3, ResNet, VGG, SimpleCNN, Efficientnet, ResNeSt, Ensemble,SeResNet, Deeplabv3\n",
    "from model import dcpResNet\n",
    "from utils import CovidCTDataset,metrics, SimCLR_loss, LabelSmoothSoftmaxCE\n",
    "from utils import autoaugment as auto\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import easydict\n",
    "\n",
    "MODEL_DICT = {\n",
    "    'densenet121': Densenet.densenet121,\n",
    "    'densenet161': Densenet.densenet161,\n",
    "    'densenet169': Densenet.densenet169,\n",
    "    'densenet201': Densenet.densenet201,\n",
    "    'resnet18': ResNet.resnet18,\n",
    "    'resnet50': ResNet.resnet50,\n",
    "    'resnet101': ResNet.resnet101,\n",
    "    'resnet152': ResNet.resnet152,\n",
    "    'seresnet50': SeResNet.se_resnet50,\n",
    "    'seresnet101': SeResNet.se_resnet101,\n",
    "    'seresnet152': SeResNet.se_resnet152,\n",
    "    'resnext101': ResNet.resnext101_32x8d,\n",
    "    'resnest50': ResNeSt.resnest50,\n",
    "    'resnest200': ResNeSt.resnest200,\n",
    "    'wide_resnet101': ResNet.wide_resnet101_2,\n",
    "    'wide_resnet50': ResNet.wide_resnet50_2,\n",
    "    'vgg16': VGG.vgg16,\n",
    "    'CNN': SimpleCNN.CNN,\n",
    "    'Linear': SimpleCNN.Linear,\n",
    "    'SimpleCNN': SimpleCNN.SimpleCNN,\n",
    "    'efficientnet-b7': Efficientnet.efficientnetb7,\n",
    "    'efficientnet-b1': Efficientnet.efficientnetb1,\n",
    "    'efficientnet-b0': Efficientnet.efficientnetb0\n",
    "}\n",
    "\n",
    "DCP_MODEL_DICT={\n",
    "    'resnet18':dcpResNet.resnet18,\n",
    "    'resnet50':dcpResNet.resnet50,\n",
    "    'resnet101':dcpResNet.resnet101,\n",
    "    'resnet152':dcpResNet.resnet152\n",
    "}\n",
    "\n",
    "def train(model, train_loader, optimizer, PRINT_INTERVAL, epoch, args, device):\n",
    "    model.train()\n",
    "    # LOSS_FUNC = LabelSmoothSoftmaxCE()\n",
    "    LOSS_FUNC = nn.CrossEntropyLoss()\n",
    "    for index, batch in enumerate(tqdm(train_loader)):\n",
    "        img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "        output = model(img)\n",
    "        optimizer.zero_grad()\n",
    "        loss = LOSS_FUNC(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (index + 1) % PRINT_INTERVAL == 0:\n",
    "            tqdm.write('Epoch [%d/%d], Iter [%d/%d], Loss: %.4f'\n",
    "                       % (epoch + 1, args.epoch, index + 1, len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, nb_classes, test_loader, device):\n",
    "    model.eval()\n",
    "    predlist = []\n",
    "    targetlist = []\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    avg_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(tqdm(test_loader)):\n",
    "            img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "            output = model(img)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            avg_val_loss += F.cross_entropy(output, label).item()/len(test_loader)\n",
    "            for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "            y_score = F.softmax(output, dim=1)\n",
    "            predlist = np.append(predlist, y_score.cpu().numpy()[:, 1])\n",
    "            targetlist = np.append(targetlist, label.long().cpu().numpy())\n",
    "\n",
    "    AUC = roc_auc_score(targetlist, predlist)\n",
    "    print(confusion_matrix)\n",
    "    precision = metrics.Precision(confusion_matrix.cpu().numpy(), nb_classes)\n",
    "    recall = metrics.Recall(confusion_matrix, nb_classes)\n",
    "    f1 = metrics.f1_score(precision, recall)\n",
    "    acc = metrics.Acc(confusion_matrix,nb_classes)\n",
    "\n",
    "    return AUC, precision, recall, f1, acc, avg_val_loss\n",
    "\n",
    "def test_mask(model, nb_classes, test_loader, device):\n",
    "    model.eval()\n",
    "    predlist = []\n",
    "    targetlist = []\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    avg_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(tqdm(test_loader)):\n",
    "            img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "            cls_pred, mask_pred = model(img)\n",
    "            _, preds = torch.max(cls_pred, 1)\n",
    "\n",
    "            avg_val_loss += F.cross_entropy(cls_pred, label).item()/len(test_loader)\n",
    "            for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "            y_score = F.softmax(cls_pred, dim=1)\n",
    "            predlist = np.append(predlist, y_score.cpu().numpy()[:, 1])\n",
    "            targetlist = np.append(targetlist, label.long().cpu().numpy())\n",
    "\n",
    "    AUC = roc_auc_score(targetlist, predlist)\n",
    "    print(confusion_matrix)\n",
    "    precision = metrics.Precision(confusion_matrix.cpu().numpy(), nb_classes)\n",
    "    recall = metrics.Recall(confusion_matrix, nb_classes)\n",
    "    f1 = metrics.f1_score(precision, recall)\n",
    "    acc = metrics.Acc(confusion_matrix,nb_classes)\n",
    "\n",
    "    return AUC, precision, recall, f1, acc, avg_val_loss\n",
    "\n",
    "def convertPaWeights2NonP(pretrained_state_dict):\n",
    "  nonpStateDict=OrderedDict()\n",
    "  for k, v in pretrained_state_dict.items():\n",
    "    nonpStateDict[k[7:]]=v\n",
    "  return nonpStateDict\n",
    "\n",
    "def buildAndTestDCPmodel(model_name, preTrainedModel, test_loader, device, R1_ratio, R2_ratio):\n",
    "    dcpModel=DCP_MODEL_DICT[model_name](num_classes=2, R1_ratio=R1_ratio, R2_ratio=R2_ratio)\n",
    "    dcpModel.loadStateFromModel(preTrainedModel)\n",
    "    \n",
    "    AUC, precision, recall, f1, acc, mean_loss = test(dcpModel, 2, test_loader, device)\n",
    "\n",
    "    print('Precision {}\\tRecall {}\\nF1 {}\\nAUC {}\\tAcc {}\\tMean Loss {}'.format(precision, recall, f1, AUC, acc,\n",
    "                                                                                mean_loss))\n",
    "\n",
    "    return acc, recall[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Device cuda\n",
      "resnet50 ['CT_COVID', 'CT_NonCOVID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /tmp/xdg-cache/torch/checkpoints/resnet50-19c8e357.pth\n",
      "\n",
      "  0%|          | 0.00/97.8M [00:00<?, ?B/s]\u001b[A\n",
      "  7%|▋         | 7.09M/97.8M [00:00<00:01, 74.3MB/s]\u001b[A\n",
      " 14%|█▍        | 14.1M/97.8M [00:00<00:01, 72.2MB/s]\u001b[A\n",
      " 20%|██        | 19.9M/97.8M [00:00<00:01, 68.4MB/s]\u001b[A\n",
      " 27%|██▋       | 26.7M/97.8M [00:00<00:01, 69.3MB/s]\u001b[A\n",
      " 36%|███▌      | 34.8M/97.8M [00:00<00:00, 73.3MB/s]\u001b[A\n",
      " 42%|████▏     | 40.7M/97.8M [00:00<00:00, 67.0MB/s]\u001b[A\n",
      " 48%|████▊     | 47.0M/97.8M [00:00<00:00, 66.8MB/s]\u001b[A\n",
      " 56%|█████▌    | 54.7M/97.8M [00:00<00:00, 70.4MB/s]\u001b[A\n",
      " 64%|██████▍   | 62.6M/97.8M [00:00<00:00, 73.6MB/s]\u001b[A\n",
      " 71%|███████   | 69.4M/97.8M [00:01<00:00, 68.2MB/s]\u001b[A\n",
      " 78%|███████▊  | 76.2M/97.8M [00:01<00:00, 69.0MB/s]\u001b[A\n",
      " 85%|████████▌ | 83.1M/97.8M [00:01<00:00, 69.9MB/s]\u001b[A\n",
      " 92%|█████████▏| 89.8M/97.8M [00:01<00:00, 65.1MB/s]\u001b[A\n",
      " 98%|█████████▊| 96.0M/97.8M [00:01<00:00, 64.5MB/s]\u001b[A\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 68.1MB/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing Full Connected\n",
      "Let's use 1 GPUs!\n",
      "...........Testing..........\n",
      "Starting R1=0.125\n",
      "R1=0.125, R2=0.125\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (7) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-955a3a52d919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# main_ensemble(models_config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-955a3a52d919>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdR1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdR2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R1=%.3f, R2=%.3f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuildAndTestDCPmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0myacc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d90a91a9cb01>\u001b[0m in \u001b[0;36mbuildAndTestDCPmodel\u001b[0;34m(model_name, preTrainedModel, test_loader, device, R1_ratio, R2_ratio)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuildAndTestDCPmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR2_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mdcpModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDCP_MODEL_DICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR2_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR2_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mdcpModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadStateFromModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreTrainedModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcpModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECE228-final/COVID-Z/model/dcpResNet.py\u001b[0m in \u001b[0;36mloadStateFromModel\u001b[0;34m(self, resnet)\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                     \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                         \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (7) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args = easydict.EasyDict({\n",
    "        'model_name':'resnet50',\n",
    "        'checkpoint_path':'./checkpoint/CT',\n",
    "        'batch_size':16,\n",
    "        'lr':1e-4,\n",
    "        'epoch':50,\n",
    "        'root_dir':'./COVID-CT/Images-processed',\n",
    "        \n",
    "        'train_COV':'./COVID-CT/Data-split/COVID/trainCT_COVID.txt',\n",
    "        'train_NonCOV':'./COVID-CT/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "        \n",
    "        'val_COV':'./COVID-CT/Data-split/COVID/valCT_COVID.txt',\n",
    "        'val_NonCOV':'./COVID-CT/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "        \n",
    "        'test_COV':'./COVID-CT/Data-split/COVID/testCT_COVID.txt',\n",
    "        'test_NonCOV':'./COVID-CT/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "        \n",
    "        'pretrained':True,\n",
    "        'save_name':'resnet50_pretrained.pt'\n",
    "    })\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device {}\".format(device))\n",
    "    # Create checkpoint file\n",
    "    save_path = os.path.join(args.checkpoint_path, args.model_name)\n",
    "    if os.path.exists(save_path) == False:\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],\n",
    "                                     std=[0.33165374, 0.33165374, 0.33165374])\n",
    "    test_trans = transforms.Compose(\n",
    "                                 [\n",
    "                                  transforms.Resize((480,480)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  normalize\n",
    "                                 ]\n",
    "                             )\n",
    "    trainset = CovidCTDataset(root_dir=args.root_dir,\n",
    "                              txt_COVID=args.train_COV,\n",
    "                              txt_NonCOVID=args.train_NonCOV,\n",
    "                                transform=transforms.Compose(\n",
    "                                    [transforms.RandomResizedCrop((480,480),scale=(0.8,1.2)),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     auto.ImageNetPolicy(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     normalize\n",
    "                                     ]\n",
    "                                ))\n",
    "    valset = CovidCTDataset(root_dir=args.root_dir,\n",
    "                            txt_COVID=args.val_COV,\n",
    "                            txt_NonCOVID=args.val_NonCOV,\n",
    "                             transform=test_trans\n",
    "                             )\n",
    "\n",
    "    testset = CovidCTDataset(root_dir=args.root_dir,\n",
    "                             txt_COVID=args.test_COV,\n",
    "                             txt_NonCOVID=args.test_NonCOV,\n",
    "                               transform=test_trans\n",
    "                               )\n",
    "\n",
    "    train_loader = DataLoader(trainset,\n",
    "                              batch_size=args.batch_size,\n",
    "                              num_workers=8,\n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size=args.batch_size)\n",
    "    test_loader = DataLoader(testset,batch_size=args.batch_size)\n",
    "\n",
    "    PRINT_INTERVAL = 10\n",
    "    nb_classes = 2\n",
    "    seg_num_class = 2\n",
    "    print(args.model_name,trainset.classes)\n",
    "\n",
    "    model = MODEL_DICT[args.model_name](num_classes=nb_classes, pretrained=args.pretrained)\n",
    "    \n",
    "    # model = Deeplabv3.DeeplabVV3(model, num_class=seg_num_class)\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model = nn.DataParallel(model).to(device)\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"GPU detected but cannot use\")\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = args.lr)\n",
    "    sheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "    # sheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_max=10)\n",
    "    # sheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=15)\n",
    "    accs = []\n",
    "    save = os.path.join(save_path,'{}'.format(args.save_name))\n",
    "\n",
    "    if not args.pretrained:\n",
    "      for epoch in range(args.epoch):\n",
    "        train(model, train_loader, optimizer, PRINT_INTERVAL, epoch, args, device)\n",
    "    \n",
    "        AUC, precision, recall, f1, acc, mean_loss = test(model, nb_classes, val_loader, device)\n",
    "        accs.append(acc)\n",
    "        print('Precision {}\\tRecall {}\\nF1 {}\\nAUC {}\\tAcc {}\\tMean Loss {}'.format(precision, recall, f1, AUC, acc, mean_loss))\n",
    "    \n",
    "        if np.max(accs) == acc:\n",
    "            torch.save(model.state_dict(), save)\n",
    "            print(\"saved\")\n",
    "        sheduler.step(epoch)\n",
    "\n",
    "    print('...........Testing..........')\n",
    "    pretrained_state_dict=torch.load(save, map_location=torch.device('cpu'))\n",
    "    if not torch.cuda.is_available():\n",
    "      pretrained_state_dict=convertPaWeights2NonP(pretrained_state_dict)\n",
    "    model.load_state_dict(pretrained_state_dict)\n",
    "\n",
    "    # acc,FN=buildAndTestDCPmodel(args.model_name, model, test_loader, device, 0.5, 0.5)\n",
    "\n",
    "    yacc,yFNs=[],[]\n",
    "    for dR1 in range(1,9):\n",
    "        yacc.append([])\n",
    "        yFNs.append([])\n",
    "        print(\"Starting R1=%.3f\"%(dR1/8))\n",
    "        for dR2 in range(1,9):\n",
    "            r1,r2=dR1/8,dR2/8\n",
    "            print(\"R1=%.3f, R2=%.3f\"%(r1,r2))\n",
    "            acc,FN=buildAndTestDCPmodel(args.model_name, model, test_loader, device, r1, r2)\n",
    "            gc.collect()\n",
    "            yacc[-1].append(acc)\n",
    "            yFNs[-1].append(FN)\n",
    "    \n",
    "    x=[d/8 for d in range(1,9)]\n",
    "    for i in range(8):\n",
    "        plt.plot(x, yacc[i])\n",
    "    plt.legend([\"R1=\"+str(i/8) for i in range(1,9)], loc='lower right')\n",
    "    for i in range(8):\n",
    "        plt.plot(x,yFNs[i], linestyle='-')\n",
    "    plt.legend([\"R1=\"+str(i/8) for i in range(1,9)], loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print(\"Start training\")\n",
    "    # search()\n",
    "    models_config = (\n",
    "        # model name, model path, weight, data_parallel\n",
    "        ('resnet152', 'resnet152_4_4_crop_480_b16_pretrained.pt', 1, True),\n",
    "        ('resnet152', 'resnet152_4_4_crop_480_b16w1.2_pretrained.pt', 1, True),\n",
    "        ('resnext101', 'resnext101_4_4_crop_480_pretrained.pt', 1, True),\n",
    "        ('densenet169', 'densenet169-480-moco-soft-COVID.pt', 1, True),\n",
    "        ('densenet169', 'densenet169_4_4_crop_480_b16_pretrained.pt', 1, True),\n",
    "        ('densenet169', 'densenet169_soft_480_pretrained.pt', 1, True),\n",
    "    )\n",
    "    # main_ensemble(models_config)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
